{"cells":[{"cell_type":"markdown","metadata":{},"source":["setup"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m/Users/dana/Desktop/dl project/keras model.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dana/Desktop/dl%20project/keras%20model.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/dana/Desktop/dl%20project/keras%20model.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mkeras\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dana/Desktop/dl%20project/keras%20model.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dana/Desktop/dl%20project/keras%20model.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpathlib\u001b[39;00m \u001b[39mimport\u001b[39;00m Path\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# DO NOT EDIT. Generated by api_gen.sh\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m \u001b[39mimport\u001b[39;00m DTypePolicy\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m \u001b[39mimport\u001b[39;00m FloatDTypePolicy\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m \u001b[39mimport\u001b[39;00m Function\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/api/__init__.py:8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"DO NOT EDIT.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[39mThis file was autogenerated. Do not edit it by hand,\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39msince your modifications would be overwritten.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m \u001b[39mimport\u001b[39;00m activations\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m \u001b[39mimport\u001b[39;00m applications\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/api/activations/__init__.py:7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"DO NOT EDIT.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[39mThis file was autogenerated. Do not edit it by hand,\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39msince your modifications would be overwritten.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mactivations\u001b[39;00m \u001b[39mimport\u001b[39;00m deserialize\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mactivations\u001b[39;00m \u001b[39mimport\u001b[39;00m get\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mactivations\u001b[39;00m \u001b[39mimport\u001b[39;00m serialize\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m \u001b[39mimport\u001b[39;00m activations\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m \u001b[39mimport\u001b[39;00m applications\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/activations/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtypes\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mactivations\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mactivations\u001b[39;00m \u001b[39mimport\u001b[39;00m celu\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mactivations\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mactivations\u001b[39;00m \u001b[39mimport\u001b[39;00m elu\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mactivations\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mactivations\u001b[39;00m \u001b[39mimport\u001b[39;00m exponential\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/activations/activations.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m \u001b[39mimport\u001b[39;00m ops\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi_export\u001b[39;00m \u001b[39mimport\u001b[39;00m keras_export\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/backend/__init__.py:10\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi_export\u001b[39;00m \u001b[39mimport\u001b[39;00m keras_export\n\u001b[0;32m---> 10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcommon\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdtypes\u001b[39;00m \u001b[39mimport\u001b[39;00m result_type\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcommon\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras_tensor\u001b[39;00m \u001b[39mimport\u001b[39;00m KerasTensor\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcommon\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras_tensor\u001b[39;00m \u001b[39mimport\u001b[39;00m any_symbolic_tensors\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/backend/common/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcommon\u001b[39;00m \u001b[39mimport\u001b[39;00m backend_utils\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcommon\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdtypes\u001b[39;00m \u001b[39mimport\u001b[39;00m result_type\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcommon\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvariables\u001b[39;00m \u001b[39mimport\u001b[39;00m AutocastScope\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcommon\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvariables\u001b[39;00m \u001b[39mimport\u001b[39;00m Variable \u001b[39mas\u001b[39;00m KerasVariable\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/backend/common/dtypes.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi_export\u001b[39;00m \u001b[39mimport\u001b[39;00m keras_export\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend\u001b[39;00m \u001b[39mimport\u001b[39;00m config\n\u001b[0;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcommon\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvariables\u001b[39;00m \u001b[39mimport\u001b[39;00m standardize_dtype\n\u001b[1;32m      7\u001b[0m BOOL_TYPES \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mbool\u001b[39m\u001b[39m\"\u001b[39m,)\n\u001b[1;32m      8\u001b[0m INT_TYPES \u001b[39m=\u001b[39m (\n\u001b[1;32m      9\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39muint8\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39muint16\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mint64\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     17\u001b[0m )\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/backend/common/variables.py:11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcommon\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstateless_scope\u001b[39;00m \u001b[39mimport\u001b[39;00m get_stateless_scope\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcommon\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstateless_scope\u001b[39;00m \u001b[39mimport\u001b[39;00m in_stateless_scope\n\u001b[0;32m---> 11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodule_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m tensorflow \u001b[39mas\u001b[39;00m tf\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnaming\u001b[39;00m \u001b[39mimport\u001b[39;00m auto_name\n\u001b[1;32m     15\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mVariable\u001b[39;00m:\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/utils/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maudio_dataset_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m audio_dataset_from_directory\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdataset_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m split_dataset\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfile_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m get_file\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/utils/audio_dataset_utils.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi_export\u001b[39;00m \u001b[39mimport\u001b[39;00m keras_export\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m dataset_utils\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodule_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m tensorflow \u001b[39mas\u001b[39;00m tf\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodule_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m tensorflow_io \u001b[39mas\u001b[39;00m tfio\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/utils/dataset_utils.py:9\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmultiprocessing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpool\u001b[39;00m \u001b[39mimport\u001b[39;00m ThreadPool\n\u001b[1;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m \u001b[39mimport\u001b[39;00m tree\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi_export\u001b[39;00m \u001b[39mimport\u001b[39;00m keras_export\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m io_utils\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/tree/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtree\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtree_api\u001b[39;00m \u001b[39mimport\u001b[39;00m assert_same_paths\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtree\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtree_api\u001b[39;00m \u001b[39mimport\u001b[39;00m assert_same_structure\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtree\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtree_api\u001b[39;00m \u001b[39mimport\u001b[39;00m flatten\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/tree/tree_api.py:8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodule_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m optree\n\u001b[1;32m      7\u001b[0m \u001b[39mif\u001b[39;00m optree\u001b[39m.\u001b[39mavailable:\n\u001b[0;32m----> 8\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtree\u001b[39;00m \u001b[39mimport\u001b[39;00m optree_impl \u001b[39mas\u001b[39;00m tree_impl\n\u001b[1;32m      9\u001b[0m \u001b[39melif\u001b[39;00m dmtree\u001b[39m.\u001b[39mavailable:\n\u001b[1;32m     10\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtree\u001b[39;00m \u001b[39mimport\u001b[39;00m dmtree_impl \u001b[39mas\u001b[39;00m tree_impl\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/tree/optree_impl.py:13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39m# Register backend-specific node classes\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39mif\u001b[39;00m backend() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtensorflow\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 13\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtrackable\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_structures\u001b[39;00m \u001b[39mimport\u001b[39;00m ListWrapper\n\u001b[1;32m     14\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtrackable\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_structures\u001b[39;00m \u001b[39mimport\u001b[39;00m _DictWrapper\n\u001b[1;32m     16\u001b[0m     optree\u001b[39m.\u001b[39mregister_pytree_node(\n\u001b[1;32m     17\u001b[0m         ListWrapper,\n\u001b[1;32m     18\u001b[0m         \u001b[39mlambda\u001b[39;00m x: (x, \u001b[39mNone\u001b[39;00m),\n\u001b[1;32m     19\u001b[0m         \u001b[39mlambda\u001b[39;00m metadata, children: ListWrapper(\u001b[39mlist\u001b[39m(children)),\n\u001b[1;32m     20\u001b[0m         namespace\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mkeras\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     21\u001b[0m     )\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/__init__.py:40\u001b[0m\n\u001b[1;32m     37\u001b[0m _os\u001b[39m.\u001b[39menviron\u001b[39m.\u001b[39msetdefault(\u001b[39m\"\u001b[39m\u001b[39mENABLE_RUNTIME_UPTIME_TELEMETRY\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[39m# Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m pywrap_tensorflow \u001b[39mas\u001b[39;00m _pywrap_tensorflow  \u001b[39m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtools\u001b[39;00m \u001b[39mimport\u001b[39;00m module_util \u001b[39mas\u001b[39;00m _module_util\n\u001b[1;32m     42\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlazy_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m KerasLazyLoader \u001b[39mas\u001b[39;00m _KerasLazyLoader\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/pywrap_tensorflow.py:34\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mplatform\u001b[39;00m \u001b[39mimport\u001b[39;00m self_check\n\u001b[1;32m     31\u001b[0m \u001b[39m# TODO(mdan): Cleanup antipattern: import for side effects.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[39m# Perform pre-load sanity checks in order to produce a more actionable error.\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m self_check\u001b[39m.\u001b[39;49mpreload_check()\n\u001b[1;32m     36\u001b[0m \u001b[39m# pylint: disable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m   \u001b[39m# This import is expected to fail if there is an explicit shared object\u001b[39;00m\n\u001b[1;32m     40\u001b[0m   \u001b[39m# dependency (with_framework_lib=true), since we do not need RTLD_GLOBAL.\u001b[39;00m\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/platform/self_check.py:63\u001b[0m, in \u001b[0;36mpreload_check\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[1;32m     51\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mCould not find the DLL(s) \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m. TensorFlow requires that these DLLs \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     52\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mbe installed in a directory that is named in your \u001b[39m\u001b[39m%%\u001b[39;00m\u001b[39mPATH\u001b[39m\u001b[39m%%\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     56\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mhttps://support.microsoft.com/help/2977003/the-latest-supported-visual-c-downloads\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     57\u001b[0m           \u001b[39m%\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m or \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(missing))\n\u001b[1;32m     58\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m   \u001b[39m# Load a library that performs CPU feature guard checking.  Doing this here\u001b[39;00m\n\u001b[1;32m     60\u001b[0m   \u001b[39m# as a preload check makes it more likely that we detect any CPU feature\u001b[39;00m\n\u001b[1;32m     61\u001b[0m   \u001b[39m# incompatibilities before we trigger them (which would typically result in\u001b[39;00m\n\u001b[1;32m     62\u001b[0m   \u001b[39m# SIGILL).\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m   \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mplatform\u001b[39;00m \u001b[39mimport\u001b[39;00m _pywrap_cpu_feature_guard\n\u001b[1;32m     64\u001b[0m   _pywrap_cpu_feature_guard\u001b[39m.\u001b[39mInfoAboutUnusedCPUFeatures()\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import numpy as np\n","import keras\n","import os\n","from pathlib import Path"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Train: 2400, Dev: 300, Test: 300\n"]}],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","# Load dataset\n","df = pd.read_csv(\"/Users/dana/Desktop/dl project/character_normalization_pairs_cleaned_output.csv\")\n","\n","# Split train (80%) and temp (20%)\n","train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42)\n","\n","# Split temp into dev (50%) and test (50%) → each gets 10% of the original data\n","dev_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n","\n","# Check sizes\n","print(f\"Train: {len(train_df)}, Dev: {len(dev_df)}, Test: {len(test_df)}\")\n","\n","# Save if needed\n","train_df.to_csv(\"/Users/dana/Desktop/dl project/train.csv\", index=False)\n","dev_df.to_csv(\"/Users/dana/Desktop/dl project/dev.csv\", index=False)\n","test_df.to_csv(\"/Users/dana/Desktop/dl project/test.csv\", index=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["           input             target\n","0        бастысы            бастысы\n","1          турып              тұрып\n","2     отыргызган         отырғызған\n","3  марапатталган  \\tмарапатталған\\t\n","4          кенес            кеңес  \n","Loaded dataset with 2400 samples\n"]}],"source":["import pandas as pd\n","import tensorflow as tf\n","import random\n","\n","# Path to your dataset\n","data_path = \"/Users/dana/Desktop/dl project/train.csv\"\n","\n","# Load the dataset\n","df = pd.read_csv(data_path)\n","\n","# Show first few rows\n","print(df.head())\n","\n","# Define training parameters\n","batch_size = 64\n","epochs = 100\n","latent_dim = 256\n","num_samples = len(df)  # Use all available samples\n","seed = 42\n","np.random.seed(seed)\n","random.seed(seed)\n","tf.random.set_seed(seed)\n","\n","print(f\"Loaded dataset with {num_samples} samples\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of samples: 2399\n","Number of unique input tokens: 45\n","Number of unique output tokens: 48\n","Max sequence length for inputs: 20\n","Max sequence length for outputs: 28\n"]}],"source":["input_texts = []\n","target_texts = []\n","input_characters = set()\n","target_characters = set()\n","\n","with open(data_path, \"r\", encoding=\"utf-8\") as f:\n","    lines = f.read().strip().split(\"\\n\")  # Remove extra spaces\n","\n","# Skip the header row and process the data\n","for line in lines[1: min(num_samples, len(lines))]:  \n","    if \",\" not in line:\n","        continue  # Skip empty or malformed lines\n","\n","    input_text, target_text = line.split(\",\")  # Use comma instead of tab\n","    target_text = \"\\t\" + target_text + \"\\n\"  # Add start and end markers\n","\n","    input_texts.append(input_text)\n","    target_texts.append(target_text)\n","\n","    for char in input_text:\n","        input_characters.add(char)\n","    for char in target_text:\n","        target_characters.add(char)\n","\n","input_characters = sorted(list(input_characters))\n","target_characters = sorted(list(target_characters))\n","num_encoder_tokens = len(input_characters)\n","num_decoder_tokens = len(target_characters)\n","max_encoder_seq_length = max(len(txt) for txt in input_texts)\n","max_decoder_seq_length = max(len(txt) for txt in target_texts)\n","\n","print(\"Number of samples:\", len(input_texts))\n","print(\"Number of unique input tokens:\", num_encoder_tokens)\n","print(\"Number of unique output tokens:\", num_decoder_tokens)\n","print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n","print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n","\n","input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n","target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n","\n","encoder_input_data = np.zeros(\n","    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n","    dtype=\"float32\",\n",")\n","decoder_input_data = np.zeros(\n","    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n","    dtype=\"float32\",\n",")\n","decoder_target_data = np.zeros(\n","    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n","    dtype=\"float32\",\n",")\n","\n","for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n","    for t, char in enumerate(input_text):\n","        encoder_input_data[i, t, input_token_index[char]] = 1.0\n","    encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n","    for t, char in enumerate(target_text):\n","        # decoder_target_data is ahead of decoder_input_data by one timestep\n","        decoder_input_data[i, t, target_token_index[char]] = 1.0\n","        if t > 0:\n","            # decoder_target_data will be ahead by one timestep\n","            # and will not include the start character.\n","            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n","    decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n","    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0\n"]},{"cell_type":"markdown","metadata":{},"source":["build the model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define an input sequence and process it.\n","encoder_inputs = keras.Input(shape=(None, num_encoder_tokens))\n","encoder = keras.layers.LSTM(latent_dim, return_state=True)\n","encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n","\n","# We discard `encoder_outputs` and only keep the states.\n","encoder_states = [state_h, state_c]\n","\n","# Set up the decoder, using `encoder_states` as initial state.\n","decoder_inputs = keras.Input(shape=(None, num_decoder_tokens))\n","\n","# We set up our decoder to return full output sequences,\n","# and to return internal states as well. We don't use the\n","# return states in the training model, but we will use them in inference.\n","decoder_lstm = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n","decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n","decoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")\n","decoder_outputs = decoder_dense(decoder_outputs)\n","\n","# Define the model that will turn\n","# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n","model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - accuracy: 0.6237 - loss: 1.9649 - val_accuracy: 0.7065 - val_loss: 1.1860\n","Epoch 2/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 0.7127 - loss: 1.1530 - val_accuracy: 0.7028 - val_loss: 1.1702\n","Epoch 3/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.7173 - loss: 1.1031 - val_accuracy: 0.7174 - val_loss: 1.0401\n","Epoch 4/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.7300 - loss: 1.0133 - val_accuracy: 0.7187 - val_loss: 1.0231\n","Epoch 5/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.7366 - loss: 0.9712 - val_accuracy: 0.7290 - val_loss: 0.9478\n","Epoch 6/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.7420 - loss: 0.9396 - val_accuracy: 0.7298 - val_loss: 0.9386\n","Epoch 7/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.7479 - loss: 0.9158 - val_accuracy: 0.7519 - val_loss: 0.8847\n","Epoch 8/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.7578 - loss: 0.8742 - val_accuracy: 0.7503 - val_loss: 0.8748\n","Epoch 9/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.7605 - loss: 0.8549 - val_accuracy: 0.7510 - val_loss: 0.8862\n","Epoch 10/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.7620 - loss: 0.8408 - val_accuracy: 0.7576 - val_loss: 0.8634\n","Epoch 11/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.7636 - loss: 0.8295 - val_accuracy: 0.7710 - val_loss: 0.8209\n","Epoch 12/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.7661 - loss: 0.8098 - val_accuracy: 0.7720 - val_loss: 0.8125\n","Epoch 13/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.7704 - loss: 0.7922 - val_accuracy: 0.7607 - val_loss: 0.8296\n","Epoch 14/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.7690 - loss: 0.7970 - val_accuracy: 0.7677 - val_loss: 0.7878\n","Epoch 15/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.7766 - loss: 0.7594 - val_accuracy: 0.7751 - val_loss: 0.7680\n","Epoch 16/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.7820 - loss: 0.7402 - val_accuracy: 0.7692 - val_loss: 0.7690\n","Epoch 17/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.7852 - loss: 0.7231 - val_accuracy: 0.7847 - val_loss: 0.7182\n","Epoch 18/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.7901 - loss: 0.7044 - val_accuracy: 0.7924 - val_loss: 0.7062\n","Epoch 19/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.7946 - loss: 0.6852 - val_accuracy: 0.7841 - val_loss: 0.7380\n","Epoch 20/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.7961 - loss: 0.6763 - val_accuracy: 0.7951 - val_loss: 0.6863\n","Epoch 21/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.8009 - loss: 0.6575 - val_accuracy: 0.7926 - val_loss: 0.7090\n","Epoch 22/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.8003 - loss: 0.6522 - val_accuracy: 0.7997 - val_loss: 0.6704\n","Epoch 23/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.8048 - loss: 0.6384 - val_accuracy: 0.7975 - val_loss: 0.6799\n","Epoch 24/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.8076 - loss: 0.6296 - val_accuracy: 0.8013 - val_loss: 0.6605\n","Epoch 25/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.8095 - loss: 0.6201 - val_accuracy: 0.8055 - val_loss: 0.6354\n","Epoch 26/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.8115 - loss: 0.6134 - val_accuracy: 0.8089 - val_loss: 0.6415\n","Epoch 27/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.8113 - loss: 0.6118 - val_accuracy: 0.7978 - val_loss: 0.6714\n","Epoch 28/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.8125 - loss: 0.6062 - val_accuracy: 0.8036 - val_loss: 0.6436\n","Epoch 29/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.8150 - loss: 0.5966 - val_accuracy: 0.8100 - val_loss: 0.6231\n","Epoch 30/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.8199 - loss: 0.5826 - val_accuracy: 0.8103 - val_loss: 0.6210\n","Epoch 31/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.8187 - loss: 0.5826 - val_accuracy: 0.8174 - val_loss: 0.6104\n","Epoch 32/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.8195 - loss: 0.5787 - val_accuracy: 0.8061 - val_loss: 0.6420\n","Epoch 33/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.8213 - loss: 0.5747 - val_accuracy: 0.8165 - val_loss: 0.5977\n","Epoch 34/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.8235 - loss: 0.5658 - val_accuracy: 0.8146 - val_loss: 0.5965\n","Epoch 35/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.8258 - loss: 0.5607 - val_accuracy: 0.8208 - val_loss: 0.5787\n","Epoch 36/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.8260 - loss: 0.5516 - val_accuracy: 0.8155 - val_loss: 0.6040\n","Epoch 37/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.8304 - loss: 0.5396 - val_accuracy: 0.8257 - val_loss: 0.5763\n","Epoch 38/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.8359 - loss: 0.5240 - val_accuracy: 0.8260 - val_loss: 0.5720\n","Epoch 39/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.8382 - loss: 0.5185 - val_accuracy: 0.8280 - val_loss: 0.5549\n","Epoch 40/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.8409 - loss: 0.5045 - val_accuracy: 0.8318 - val_loss: 0.5445\n","Epoch 41/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.8458 - loss: 0.4969 - val_accuracy: 0.8320 - val_loss: 0.5379\n","Epoch 42/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.8445 - loss: 0.4950 - val_accuracy: 0.8201 - val_loss: 0.5995\n","Epoch 43/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.8461 - loss: 0.4914 - val_accuracy: 0.8387 - val_loss: 0.5271\n","Epoch 44/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.8501 - loss: 0.4778 - val_accuracy: 0.8412 - val_loss: 0.5209\n","Epoch 45/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.8526 - loss: 0.4702 - val_accuracy: 0.8443 - val_loss: 0.5176\n","Epoch 46/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.8576 - loss: 0.4576 - val_accuracy: 0.8467 - val_loss: 0.5178\n","Epoch 47/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.8558 - loss: 0.4578 - val_accuracy: 0.8478 - val_loss: 0.5033\n","Epoch 48/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.8598 - loss: 0.4433 - val_accuracy: 0.8435 - val_loss: 0.5107\n","Epoch 49/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.8598 - loss: 0.4420 - val_accuracy: 0.8470 - val_loss: 0.5009\n","Epoch 50/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.8631 - loss: 0.4344 - val_accuracy: 0.8344 - val_loss: 0.5492\n","Epoch 51/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.8603 - loss: 0.4373 - val_accuracy: 0.8512 - val_loss: 0.4935\n","Epoch 52/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.8676 - loss: 0.4186 - val_accuracy: 0.8463 - val_loss: 0.4967\n","Epoch 53/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.8671 - loss: 0.4130 - val_accuracy: 0.8496 - val_loss: 0.4823\n","Epoch 54/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.8710 - loss: 0.4042 - val_accuracy: 0.8469 - val_loss: 0.5099\n","Epoch 55/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.8728 - loss: 0.4015 - val_accuracy: 0.8513 - val_loss: 0.4815\n","Epoch 56/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.8759 - loss: 0.3907 - val_accuracy: 0.8551 - val_loss: 0.4690\n","Epoch 57/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.8793 - loss: 0.3789 - val_accuracy: 0.8548 - val_loss: 0.4736\n","Epoch 58/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.8809 - loss: 0.3732 - val_accuracy: 0.8567 - val_loss: 0.4694\n","Epoch 59/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.8863 - loss: 0.3612 - val_accuracy: 0.8549 - val_loss: 0.4722\n","Epoch 60/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 0.8843 - loss: 0.3621 - val_accuracy: 0.8571 - val_loss: 0.4703\n","Epoch 61/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.8849 - loss: 0.3600 - val_accuracy: 0.8574 - val_loss: 0.4643\n","Epoch 62/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.8909 - loss: 0.3428 - val_accuracy: 0.8635 - val_loss: 0.4454\n","Epoch 63/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 0.8938 - loss: 0.3346 - val_accuracy: 0.8609 - val_loss: 0.4647\n","Epoch 64/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.8903 - loss: 0.3396 - val_accuracy: 0.8519 - val_loss: 0.4854\n","Epoch 65/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.8955 - loss: 0.3256 - val_accuracy: 0.8582 - val_loss: 0.4587\n","Epoch 66/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.8971 - loss: 0.3225 - val_accuracy: 0.8609 - val_loss: 0.4638\n","Epoch 67/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 0.8989 - loss: 0.3141 - val_accuracy: 0.8647 - val_loss: 0.4417\n","Epoch 68/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.9044 - loss: 0.2999 - val_accuracy: 0.8653 - val_loss: 0.4458\n","Epoch 69/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.9065 - loss: 0.2943 - val_accuracy: 0.8638 - val_loss: 0.4426\n","Epoch 70/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 0.9077 - loss: 0.2890 - val_accuracy: 0.8652 - val_loss: 0.4468\n","Epoch 71/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.9098 - loss: 0.2845 - val_accuracy: 0.8601 - val_loss: 0.4522\n","Epoch 72/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.9116 - loss: 0.2787 - val_accuracy: 0.8646 - val_loss: 0.4393\n","Epoch 73/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.9123 - loss: 0.2758 - val_accuracy: 0.8662 - val_loss: 0.4419\n","Epoch 74/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.9163 - loss: 0.2648 - val_accuracy: 0.8674 - val_loss: 0.4474\n","Epoch 75/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.9163 - loss: 0.2617 - val_accuracy: 0.8661 - val_loss: 0.4497\n","Epoch 76/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.9203 - loss: 0.2506 - val_accuracy: 0.8643 - val_loss: 0.4520\n","Epoch 77/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.9241 - loss: 0.2402 - val_accuracy: 0.8695 - val_loss: 0.4395\n","Epoch 78/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.9220 - loss: 0.2416 - val_accuracy: 0.8667 - val_loss: 0.4436\n","Epoch 79/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 0.9289 - loss: 0.2267 - val_accuracy: 0.8679 - val_loss: 0.4519\n","Epoch 80/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 0.9290 - loss: 0.2257 - val_accuracy: 0.8711 - val_loss: 0.4434\n","Epoch 81/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.9289 - loss: 0.2233 - val_accuracy: 0.8622 - val_loss: 0.4610\n","Epoch 82/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.9317 - loss: 0.2156 - val_accuracy: 0.8728 - val_loss: 0.4361\n","Epoch 83/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.9357 - loss: 0.2063 - val_accuracy: 0.8719 - val_loss: 0.4455\n","Epoch 84/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.9368 - loss: 0.1999 - val_accuracy: 0.8705 - val_loss: 0.4677\n","Epoch 85/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.9375 - loss: 0.2009 - val_accuracy: 0.8685 - val_loss: 0.4568\n","Epoch 86/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.9388 - loss: 0.1913 - val_accuracy: 0.8689 - val_loss: 0.4515\n","Epoch 87/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.9454 - loss: 0.1790 - val_accuracy: 0.8734 - val_loss: 0.4539\n","Epoch 88/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.9461 - loss: 0.1741 - val_accuracy: 0.8671 - val_loss: 0.4714\n","Epoch 89/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.9454 - loss: 0.1769 - val_accuracy: 0.8704 - val_loss: 0.4750\n","Epoch 90/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 0.9491 - loss: 0.1688 - val_accuracy: 0.8729 - val_loss: 0.4573\n","Epoch 91/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.9512 - loss: 0.1592 - val_accuracy: 0.8682 - val_loss: 0.4858\n","Epoch 92/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 0.9522 - loss: 0.1555 - val_accuracy: 0.8650 - val_loss: 0.4831\n","Epoch 93/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 0.9552 - loss: 0.1483 - val_accuracy: 0.8735 - val_loss: 0.4673\n","Epoch 94/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.9593 - loss: 0.1375 - val_accuracy: 0.8729 - val_loss: 0.4731\n","Epoch 95/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - accuracy: 0.9605 - loss: 0.1375 - val_accuracy: 0.8698 - val_loss: 0.4867\n","Epoch 96/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.9602 - loss: 0.1356 - val_accuracy: 0.8735 - val_loss: 0.4688\n","Epoch 97/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.9639 - loss: 0.1257 - val_accuracy: 0.8710 - val_loss: 0.4809\n","Epoch 98/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.9665 - loss: 0.1200 - val_accuracy: 0.8726 - val_loss: 0.4765\n","Epoch 99/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.9667 - loss: 0.1171 - val_accuracy: 0.8728 - val_loss: 0.4861\n","Epoch 100/100\n","\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.9673 - loss: 0.1139 - val_accuracy: 0.8687 - val_loss: 0.4957\n"]}],"source":["from keras.callbacks import EarlyStopping\n","\n","early_stopping = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n","\n","model.compile(\n","    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",")\n","model.fit(\n","    [encoder_input_data, decoder_input_data],\n","    decoder_target_data,\n","    batch_size=batch_size,\n","    epochs=100,\n","    validation_split=0.1,\n",")\n","# Save model\n","model.save(\"/Users/dana/Desktop/dl project/100_epochs_s2s_model.keras\")"]},{"cell_type":"markdown","metadata":{},"source":["Run inference (sampling)\n","\n","encode input and retrieve initial decoder state\n","\n","run one step of decoder with this initial state and a \"start of sequence\" token as target. Output will be the next target token.\n","\n","Repeat with the current target token and current states"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define sampling models\n","# Restore the model and construct the encoder and decoder.\n","model = keras.models.load_model(\"/Users/dana/Desktop/dl project/100_epochs_s2s_model.keras\")\n","\n","encoder_inputs = model.input[0]  # input_1\n","encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output  # lstm_1\n","encoder_states = [state_h_enc, state_c_enc]\n","encoder_model = keras.Model(encoder_inputs, encoder_states)\n","\n","decoder_inputs = model.input[1]  # input_2\n","decoder_state_input_h = keras.Input(shape=(latent_dim,))\n","decoder_state_input_c = keras.Input(shape=(latent_dim,))\n","decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n","decoder_lstm = model.layers[3]\n","decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n","    decoder_inputs, initial_state=decoder_states_inputs\n",")\n","decoder_states = [state_h_dec, state_c_dec]\n","decoder_dense = model.layers[4]\n","decoder_outputs = decoder_dense(decoder_outputs)\n","decoder_model = keras.Model(\n","    [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",")\n","\n","# Reverse-lookup token index to decode sequences back to\n","# something readable.\n","reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n","reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n","\n","\n","def decode_sequence(input_seq):\n","    # Encode the input as state vectors.\n","    states_value = encoder_model.predict(input_seq, verbose=0)\n","\n","    # Generate empty target sequence of length 1.\n","    target_seq = np.zeros((1, 1, num_decoder_tokens))\n","    # Populate the first character of target sequence with the start character.\n","    target_seq[0, 0, target_token_index[\"\\t\"]] = 1.0\n","\n","    # Sampling loop for a batch of sequences\n","    # (to simplify, here we assume a batch of size 1).\n","    stop_condition = False\n","    decoded_sentence = \"\"\n","    while not stop_condition:\n","        output_tokens, h, c = decoder_model.predict(\n","            [target_seq] + states_value, verbose=0\n","        )\n","\n","        # Sample a token\n","        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","        sampled_char = reverse_target_char_index[sampled_token_index]\n","        decoded_sentence += sampled_char\n","\n","        # Exit condition: either hit max length\n","        # or find stop character.\n","        if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n","            stop_condition = True\n","\n","        # Update the target sequence (of length 1).\n","        target_seq = np.zeros((1, 1, num_decoder_tokens))\n","        target_seq[0, 0, sampled_token_index] = 1.0\n","\n","        # Update states\n","        states_value = [h, c]\n","    return decoded_sentence"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["-\n","Input sentence: бастысы\n","Decoded sentence:  бастысы\n","\n","-\n","Input sentence: турып\n","Decoded sentence:  тұрып\n","\n","-\n","Input sentence: отыргызган\n","Decoded sentence:  отырғыздық\n","\n","-\n","Input sentence: марапатталган\n","Decoded sentence:  марапаттарлың\n","\n","-\n","Input sentence: кенес\n","Decoded sentence:  кеңес  \n","\n","-\n","Input sentence: шыгармашылык\n","Decoded sentence:  шығаршашылық\n","\n","-\n","Input sentence: оралган\n","Decoded sentence:  оралады\t\n","\n","-\n","Input sentence: улык\n","Decoded sentence: \tұлық\t\n","\n","-\n","Input sentence: жарым\n","Decoded sentence:  жарым\n","\n","-\n","Input sentence: диалогка\n","Decoded sentence:  дарлақтың\n","\n","-\n","Input sentence: карттарымыздан\n","Decoded sentence:  қартатырымызда\n","\n","-\n","Input sentence: дереу\n","Decoded sentence: дереу\n","\n","-\n","Input sentence: инфракурылым\n","Decoded sentence:  нинұрақтылмес\n","\n","-\n","Input sentence: барі\n","Decoded sentence:  бария\n","\n","-\n","Input sentence: болганымен\n","Decoded sentence:  болғанымен  \n","\n","-\n","Input sentence: башкуртша\n","Decoded sentence:  бақшартты\n","\n","-\n","Input sentence: жак\n","Decoded sentence:  жақ\t\n","\n","-\n","Input sentence: онай\n","Decoded sentence:  оңай  \n","\n","-\n","Input sentence: сизди\n","Decoded sentence: сізді\n","\n","-\n","Input sentence: жатыр\n","Decoded sentence:  жатыр  \n","\n","-\n","Input sentence: аукымды\n","Decoded sentence:  ауқымда\n","\n","-\n","Input sentence: мен\n","Decoded sentence: мен\n","\n","-\n","Input sentence: будан\n","Decoded sentence:  бұдай\n","\n","-\n","Input sentence: аздаган\n","Decoded sentence:  аззаған\n","\n","-\n","Input sentence: журнагы\n","Decoded sentence:  жұраным\n","\n","-\n","Input sentence: кабилеттер\n","Decoded sentence:  қабіктелті\n","\n","-\n","Input sentence: билгениниз\n","Decoded sentence: білгеніңіз\n","\n","-\n","Input sentence: инимди\n","Decoded sentence:  інімде  \n","\n","-\n","Input sentence: енбкетеры\n","Decoded sentence:  еңбектері\n","\n","-\n","Input sentence: ужаткан\n","Decoded sentence: жатқанша\n","\n","-\n","Input sentence: еркек\n","Decoded sentence: еркек\n","\n","-\n","Input sentence: жырауларды\n","Decoded sentence:  жырауларды\n","\n","-\n","Input sentence: курыстырмай\n","Decoded sentence:  құрыстырмен \n","\n","-\n","Input sentence: препараттар\n","Decoded sentence:  парекішілет\n","\n","-\n","Input sentence: саналады\n","Decoded sentence:  саналады\n","\n","-\n","Input sentence: еси\n","Decoded sentence: есі\n","\n","-\n","Input sentence: ардакты\n","Decoded sentence:  ардақты  \n","\n","-\n","Input sentence: куралаи\n","Decoded sentence:  қарлақты\n","\n","-\n","Input sentence: апта\n","Decoded sentence:  апта\n","\n","-\n","Input sentence: бір\n","Decoded sentence: бір\n","\n","-\n","Input sentence: когамда\n","Decoded sentence:  қоғамда  \n","\n","-\n","Input sentence: жылдык\n","Decoded sentence:  жылдым  \n","\n","-\n","Input sentence: копшилик\n","Decoded sentence:  көпшілік\t\n","\n","-\n","Input sentence: зиялылары\n","Decoded sentence:  зиялылары\n","\n","-\n","Input sentence: ойын\n","Decoded sentence:  ойын\n","\n","-\n","Input sentence: берды\n","Decoded sentence:  берді  \n","\n","-\n","Input sentence: сойылын\n","Decoded sentence:  сойысын\n","\n","-\n","Input sentence: канша\n","Decoded sentence: қанша\n","\n","-\n","Input sentence: ари\n","Decoded sentence: әрі\n","\n","-\n","Input sentence: терминдерынын\n","Decoded sentence:  тетимделіндік  \n","\n"]}],"source":["for seq_index in range(50):\n","    # Take one sequence (part of the training set)\n","    # for trying out decoding.\n","    input_seq = encoder_input_data[seq_index : seq_index + 1]\n","    decoded_sentence = decode_sequence(input_seq)\n","    print(\"-\")\n","    print(\"Input sentence:\", input_texts[seq_index])\n","    print(\"Decoded sentence:\", decoded_sentence)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["-\n","Input: бастысы\n","Reference: бастысы\n","Prediction: бастысы\n","BLEU Score: 100.00\n","-\n","Input: турып\n","Reference: тұрып\n","Prediction: тұрып\n","BLEU Score: 100.00\n","-\n","Input: отыргызган\n","Reference: отырғызған\n","Prediction: отырғыздық\n","BLEU Score: 0.00\n","-\n","Input: марапатталган\n","Reference: марапатталған\n","Prediction: марапаттарлың\n","BLEU Score: 0.00\n","-\n","Input: кенес\n","Reference: кеңес\n","Prediction: кеңес\n","BLEU Score: 100.00\n","-\n","Input: шыгармашылык\n","Reference: шығармашылық\n","Prediction: шығаршашылық\n","BLEU Score: 0.00\n","-\n","Input: оралган\n","Reference: оралған\n","Prediction: оралады\n","BLEU Score: 0.00\n","-\n","Input: улык\n","Reference: ұлық\n","Prediction: ұлық\n","BLEU Score: 100.00\n","-\n","Input: жарым\n","Reference: жарым\n","Prediction: жарым\n","BLEU Score: 100.00\n","-\n","Input: диалогка\n","Reference: диалогқа\n","Prediction: дарлақтың\n","BLEU Score: 0.00\n","-\n","Input: карттарымыздан\n","Reference: қарттарымыздан\n","Prediction: қартатырымызда\n","BLEU Score: 0.00\n","-\n","Input: дереу\n","Reference: дереу\n","Prediction: дереу\n","BLEU Score: 100.00\n","-\n","Input: инфракурылым\n","Reference: инфрақұрылым\n","Prediction: нинұрақтылмес\n","BLEU Score: 0.00\n","-\n","Input: барі\n","Reference: бәрі\n","Prediction: бария\n","BLEU Score: 0.00\n","-\n","Input: болганымен\n","Reference: болғанымен\n","Prediction: болғанымен\n","BLEU Score: 100.00\n","-\n","Input: башкуртша\n","Reference: башқұртша\n","Prediction: бақшартты\n","BLEU Score: 0.00\n","-\n","Input: жак\n","Reference: жақ\n","Prediction: жақ\n","BLEU Score: 100.00\n","-\n","Input: онай\n","Reference: оңай\n","Prediction: оңай\n","BLEU Score: 100.00\n","-\n","Input: сизди\n","Reference: сізді\n","Prediction: сізді\n","BLEU Score: 100.00\n","-\n","Input: жатыр\n","Reference: жатыр\n","Prediction: жатыр\n","BLEU Score: 100.00\n","-\n","Input: аукымды\n","Reference: ауқымды\n","Prediction: ауқымда\n","BLEU Score: 0.00\n","-\n","Input: мен\n","Reference: мен\n","Prediction: мен\n","BLEU Score: 100.00\n","-\n","Input: будан\n","Reference: бұдан\n","Prediction: бұдай\n","BLEU Score: 0.00\n","-\n","Input: аздаган\n","Reference: аздаған\n","Prediction: аззаған\n","BLEU Score: 0.00\n","-\n","Input: журнагы\n","Reference: жұрнағы\n","Prediction: жұраным\n","BLEU Score: 0.00\n","-\n","Input: кабилеттер\n","Reference: қабілеттер\n","Prediction: қабіктелті\n","BLEU Score: 0.00\n","-\n","Input: билгениниз\n","Reference: білгеніңіз\n","Prediction: білгеніңіз\n","BLEU Score: 100.00\n","-\n","Input: инимди\n","Reference: інімді\n","Prediction: інімде\n","BLEU Score: 0.00\n","-\n","Input: енбкетеры\n","Reference: еңбектері\n","Prediction: еңбектері\n","BLEU Score: 100.00\n","-\n","Input: ужаткан\n","Reference: жатырған\n","Prediction: жатқанша\n","BLEU Score: 0.00\n","-\n","Input: еркек\n","Reference: еркек\n","Prediction: еркек\n","BLEU Score: 100.00\n","-\n","Input: жырауларды\n","Reference: жырауларды\n","Prediction: жырауларды\n","BLEU Score: 100.00\n","-\n","Input: курыстырмай\n","Reference: құрыстырмай\n","Prediction: құрыстырмен\n","BLEU Score: 0.00\n","-\n","Input: препараттар\n","Reference: препараттар\n","Prediction: парекішілет\n","BLEU Score: 0.00\n","-\n","Input: саналады\n","Reference: саналады\n","Prediction: саналады\n","BLEU Score: 100.00\n","-\n","Input: еси\n","Reference: есі\n","Prediction: есі\n","BLEU Score: 100.00\n","-\n","Input: ардакты\n","Reference: ардақты\n","Prediction: ардақты\n","BLEU Score: 100.00\n","-\n","Input: куралаи\n","Reference: куралаи\n","Prediction: қарлақты\n","BLEU Score: 0.00\n","-\n","Input: апта\n","Reference: апта\n","Prediction: апта\n","BLEU Score: 100.00\n","-\n","Input: бір\n","Reference: бір\n","Prediction: бір\n","BLEU Score: 100.00\n","-\n","Input: когамда\n","Reference: қоғамда\n","Prediction: қоғамда\n","BLEU Score: 100.00\n","-\n","Input: жылдык\n","Reference: жылдық\n","Prediction: жылдым\n","BLEU Score: 0.00\n","-\n","Input: копшилик\n","Reference: көпшілік\n","Prediction: көпшілік\n","BLEU Score: 100.00\n","-\n","Input: зиялылары\n","Reference: зиялылары\n","Prediction: зиялылары\n","BLEU Score: 100.00\n","-\n","Input: ойын\n","Reference: ойын\n","Prediction: ойын\n","BLEU Score: 100.00\n","-\n","Input: берды\n","Reference: берді\n","Prediction: берді\n","BLEU Score: 100.00\n","-\n","Input: сойылын\n","Reference: сойылын\n","Prediction: сойысын\n","BLEU Score: 0.00\n","-\n","Input: канша\n","Reference: қанша\n","Prediction: қанша\n","BLEU Score: 100.00\n","-\n","Input: ари\n","Reference: әрі\n","Prediction: әрі\n","BLEU Score: 100.00\n","-\n","Input: терминдерынын\n","Reference: терминдерінің\n","Prediction: тетимделіндік\n","BLEU Score: 0.00\n","\n","Average BLEU Score: 56.00\n"]}],"source":["import sacrebleu\n","\n","def compute_bleu(reference, hypothesis):\n","    return sacrebleu.sentence_bleu(hypothesis, [reference]).score\n","\n","total_bleu = 0.0\n","num_samples = 50  # Or use len(input_texts)\n","\n","for seq_index in range(num_samples):\n","    input_seq = encoder_input_data[seq_index : seq_index + 1]\n","    decoded_sentence = decode_sequence(input_seq)\n","\n","    reference = target_texts[seq_index].strip()\n","    hypothesis = decoded_sentence.strip()\n","\n","    bleu_score = compute_bleu(reference, hypothesis)\n","    total_bleu += bleu_score\n","\n","    print(\"-\")\n","    print(f\"Input: {input_texts[seq_index]}\")\n","    print(f\"Reference: {reference}\")\n","    print(f\"Prediction: {hypothesis}\")\n","    print(f\"BLEU Score: {bleu_score:.2f}\")\n","\n","# Compute average BLEU score\n","average_bleu = total_bleu / num_samples\n","print(f\"\\nAverage BLEU Score: {average_bleu:.2f}\")\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["epochs 100 - Average BLEU Score: 32.00\n","\n","epochs 100 - Average BLEU Score: 56.00 (dataset increased to 3000)\n","\n","epochs 300 - Average BLEU Score: 98.00\n","\n","epochs 150 w early stopping - Average BLEU Score: 94.00"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from tensorflow.keras.models import load_model\n","\n","model_100 = load_model(\"/Users/dana/Desktop/dl project/less_data/100_epochs_s2s_model.keras\")\n","model_300 = load_model(\"/Users/dana/Desktop/dl project/less_data/300_epochs_s2s_model.keras\")  # Adjust if needed\n","model_150_early_stopping = load_model(\"/Users/dana/Desktop/dl project/less_data/150_epochs_early_stopping_s2s_model.keras\")\n","model_100_data_increased = load_model(\"/Users/dana/Desktop/dl project/100_epochs_s2s_model.keras\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Initialize test data arrays\n","encoder_test_data = np.zeros(\n","    (len(test_df), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\n",")\n","decoder_test_data = np.zeros(\n","    (len(test_df), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",")\n","decoder_target_test = np.zeros(\n","    (len(test_df), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",")\n","\n","# Process each test sample\n","for i, (input_text, target_text) in enumerate(zip(test_df[\"input\"], test_df[\"target\"])):\n","    input_text = str(input_text)  # Ensure input_text is a string\n","    target_text = str(target_text)  # Ensure target_text is a string\n","\n","    for t, char in enumerate(input_text):\n","        if char in input_token_index:  # Ensure the character exists in training vocab\n","            encoder_test_data[i, t, input_token_index[char]] = 1.0\n","    encoder_test_data[i, t + 1 :, input_token_index[\" \"]] = 1.0  # Padding\n","\n","    target_text = \"\\t\" + target_text + \"\\n\"  # Add start and end markers\n","    for t, char in enumerate(target_text):\n","        if char in target_token_index:\n","            decoder_test_data[i, t, target_token_index[char]] = 1.0\n","            if t > 0:\n","                decoder_target_test[i, t - 1, target_token_index[char]] = 1.0\n","    decoder_test_data[i, t + 1 :, target_token_index[\" \"]] = 1.0  # Padding\n","    decoder_target_test[i, t:, target_token_index[\" \"]] = 1.0\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7377 - loss: 1.8171\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7359 - loss: 2.9873\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7344 - loss: 3.0047\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8711 - loss: 0.4789\n","100 epochs - Loss: 1.7866599559783936, Accuracy: 0.7389285564422607\n","300 epochs - Loss: 2.9398956298828125, Accuracy: 0.7383333444595337\n","150 epochs - Loss: 2.9501419067382812, Accuracy: 0.7372618913650513\n","100 epochs - Loss: 0.4822866916656494, Accuracy: 0.871666669845581\n"]}],"source":["# Evaluate models properly\n","loss_100, acc_100 = model_100.evaluate(\n","    [encoder_test_data, decoder_test_data], decoder_target_test\n",")\n","loss_300, acc_300 = model_300.evaluate(\n","    [encoder_test_data, decoder_test_data], decoder_target_test\n",")\n","\n","loss_150, acc_150 = model_150_early_stopping.evaluate(\n","    [encoder_test_data, decoder_test_data], decoder_target_test\n",")\n","\n","loss_100_data_increased, acc_100_data_increased = model_100_data_increased.evaluate(\n","    [encoder_test_data, decoder_test_data], decoder_target_test\n",")\n","\n","print(f\"100 epochs - Loss: {loss_100}, Accuracy: {acc_100}\")\n","print(f\"300 epochs - Loss: {loss_300}, Accuracy: {acc_300}\")\n","print(f\"150 epochs - Loss: {loss_150}, Accuracy: {acc_150}\")\n","print(f\"100 epochs - Loss: {loss_100_data_increased}, Accuracy: {acc_100_data_increased}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["Accuracy is similar for both (small improvement at 300 epochs).\n","\n","Loss is much higher at 300 epochs → This suggests overfitting.\n","\n","The model has memorized training data instead of generalizing well.\n","It struggles with new (test) data."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","Model (100 epochs) Prediction: [[3.2895666e-02 4.7676418e-05 4.0806106e-01 ... 6.6174733e-05\n","  2.0410349e-03 3.5746729e-03]\n"," [1.1848162e-03 2.5758054e-04 2.1448459e-03 ... 1.0539153e-04\n","  1.6127259e-03 5.0183279e-03]\n"," [2.6871778e-05 6.7502573e-05 6.0543658e-07 ... 1.3142207e-04\n","  1.2852052e-04 9.7041702e-05]\n"," ...\n"," [9.1742782e-09 8.9145203e-08 9.9999666e-01 ... 5.3400090e-10\n","  2.1502541e-10 2.8338000e-08]\n"," [1.0000387e-08 7.7693812e-08 9.9999702e-01 ... 4.0884443e-10\n","  1.7675846e-10 2.2647091e-08]\n"," [1.1179472e-08 7.9912589e-08 9.9999654e-01 ... 3.5991504e-10\n","  1.6550590e-10 1.9457390e-08]]\n","Model (300 epochs) Prediction: [[1.80835486e-04 6.58743948e-10 8.87625277e-01 ... 1.94641274e-07\n","  2.28985955e-05 1.64100318e-04]\n"," [9.13821282e-07 5.66816316e-10 2.03385844e-05 ... 4.74317119e-07\n","  2.00994091e-05 1.75508831e-04]\n"," [1.05572141e-07 5.34687850e-09 1.35549086e-10 ... 2.51147485e-05\n","  4.19008484e-06 1.58476978e-05]\n"," ...\n"," [1.36660785e-16 1.38433400e-13 1.00000000e+00 ... 3.12549194e-14\n","  6.75659547e-14 1.72225168e-11]\n"," [1.13418572e-16 1.29720629e-13 1.00000000e+00 ... 3.06173239e-14\n","  4.22600865e-14 1.08131360e-11]\n"," [9.87877983e-17 1.53295535e-13 1.00000000e+00 ... 2.77160581e-14\n","  2.59588256e-14 1.00050575e-11]]\n"]}],"source":["preds_100 = model_100.predict([encoder_test_data, decoder_test_data])\n","preds_300 = model_300.predict([encoder_test_data, decoder_test_data])\n","\n","# Example: Print first test sample\n","print(\"Model (100 epochs) Prediction:\", preds_100[0])\n","print(\"Model (300 epochs) Prediction:\", preds_300[0])\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.0"}},"nbformat":4,"nbformat_minor":2}
